\chapter{Algorithms for the Online Portfolio Optimization Problem}\label{ch:algos}

In this section we will review the state of the art algorithms for the Online Portfolio Optimization problem and discuss their theoretical guarantees, and haw this algorithm can be generated by the algorithms for Online Learning with expert advice and Online Optimization we encountered in Chapter \ref{ch:OnlineLearning}.

The setting is the one described in Section \ref{sec:OPO}, in particular $\Delta=\Delta_{N-1}\subset \mathbb R^N$ is the $N$-simplex, and an element $\mathbf x_t\in\Delta$ describes the allocation into $N$ stocks for the $t$-th period.

As is commonly done in the portfolio allocation literature~\cite{agarwal2006algorithms}, we assume that the price of the assets does not change too much during two consecutive rounds, or, formally:

\begin{assumption} \label{ass:nojunk}
    %  Given the OPO framework, 
     There exist two finite constants $\epsilon_l, \epsilon_u \in \mathbb{R}^+$ s.t.~the price relatives~$y_{j,t} \in [\epsilon_l, \epsilon_u]$, with $0 < \epsilon_l \leq \epsilon_u < +\infty$, for each round $t \in \{ 1, \ldots, T \}$ and each asset $j \in \{1, \ldots, N \}$.
\end{assumption}

Notice that under Assumption~\ref{ass:nojunk}, it is possible to bound the $L_1$, $L_2$ and the $L_\infty$ gradient of the loss as follows:\todo{check}

\begin{equation} \label{eq:bounded_gradient}
    ||\nabla \log (\langle \mathbf{x}_t, \mathbf{y}_t) \rangle||_1 \leq \frac{N\epsilon_u}{\epsilon_l}:=G_1.
\end{equation}

\begin{equation} \label{eq:bounded_gradient}
    ||\nabla \log (\langle \mathbf{x}_t, \mathbf{y}_t) \rangle||_2 \leq \frac{\epsilon_u \sqrt{N}}{\epsilon_l}:=G_2.
\end{equation}

\begin{equation} \label{eq:bounded_gradient}
    ||\nabla \log (\langle \mathbf{x}_t, \mathbf{y}_t) \rangle||_\infty \leq \frac{\epsilon_u }{\epsilon_l}:=G_\infty.
\end{equation}

Since we will compare multiple algorithms we introduce the notation: $R_T(\mathcal A)$, when speaking about the regret at time $T$ of an online learner $\mathcal A$, the same notation applies with the total regret $R_T^C$ or the regret on the costs $C_T$, defined in Section \ref{sec:transaction_costs}.

\section{Universal Portfolios}
The Universal Portfolios (UP) algorithm has the best theoretical guarantees among the algorithm for Online Portfolio Optimization. 

\begin{definition}(Universal Portfolios).
\begin{equation}\label{eq:UP}
\mathbf x_{t+1}=\frac{\int_{\Delta}\mathbf x W_t(\mathbf x)d\mathbf x}{\int_{\Delta} W_t(\mathbf x)d\mathbf x}
\end{equation}
\end{definition}

Note that this algorithm is the Continuous Mixture Forecaster for exp-concave losses, described in Section \ref{sec:exp-concave-mixture}, since the logarithmic loss is exp concave with $\nu=1$. With the analysis described in Section \ref{sec:laplace_mixture}.

Hence we have that 
\begin{equation}
R_T(UP)\le(N-1)\log(T+1)
\end{equation}

Clearly, the UP algorithm is computationally hard as it involves integration over a $N$-simplex. Indeed, there is an extensive research that looks into efficient implementations of the UP algorithm \cite{kalai2002efficient}.

Equation \eqref{eq:UP} can be refined with:

\begin{equation}\label{eq:general_UP}
\mathbf x_{t+1}=\frac{\int_{\Delta}\mathbf x W_t(\mathbf x)\mu(\mathbf x)d\mathbf x}{\int_{\Delta} W_t(\mathbf x)\mu(\mathbf x)d\mathbf x},
\end{equation}

where $\mu(\mathbf x)$ is a distribution over $\Delta_{N-1}$, there are choices of $\mu(\mathbf x)$ for which we can obtain slightly better constants for the regret bound.


\section{Exponential Gradient}

The Exponential Gradient (EG) algorithm is a specification of the OMD algorithm described in Section \ref{sec:OMD}, by using as the Bregman divergence the Kullbackâ€“Leibler divergence $d_\psi(\mathbf x,\mathbf y)=KL(\mathbf x,\mathbf y)=\sum\limits_{i=1}^Nx_i\log(x_i/y_i)$, and $\eta_t=\eta$ as constant sequence of learning rates. The update rule for EG in this case becomes:

\begin{definition}(Exponential Gradient).
\begin{equation}\label{eq:update_EG}
\mathbf x_{t+1}=\arg\min\limits_{x\in\Delta_{N-1}} KL(\mathbf x,\mathbf x_t)-\eta_t\left\langle \frac{\mathbf x_t}{\langle \mathbf x_t,\mathbf y_t\rangle},\mathbf x-\mathbf x_t\right\rangle
\end{equation}
\end{definition}

The update rule in Equation \eqref{eq:update_EG} can be solved analytically \cite{helmbold1998line}, giving the following closed update 

\begin{equation}\label{eq:update_EG_closed}
x_{i,t+1}=\frac{x_{j,t}\exp\left(\eta_t{y_{j,t}}/\langle\mathbf x_t,\mathbf y_t\rangle\right)}{\sum\limits_{j=1}^Nx_{j,t}\exp\left(\eta_t{y_{j,t}}/\langle\mathbf x_t,\mathbf y_t\rangle\right)}, \forall i\in1,\ldots,N
\end{equation}

This update rule is also of the kind of an Weighted Average Forecaster described in Section \ref{sec:existence_of_no_regret}, in particular it is a special kind of Exponentially Weighted Forecaster of Definition \ref{def:ewf}.

We know that $\psi(\mathbf x)=\sum\limits_{i=1}^Nx_i\log(x_i)$ is $1$-strong convex with respect to the $L_1$ norm $||\cdot||_1$ \cite{shalev2007online}, and so we have that $KL(\mathbf x,\mathbf x_t)\ge\frac{1}{2}||\mathbf x-\mathbf x_t||_1$.

Moreover, we we can bound the $L_1$ diameter $D_1$ of the simplex $\Delta_{N-1}$ as: 
$$D_1=\sup\limits_{\mathbf x,\mathbf y\in\Delta_{N-1}}||\mathbf x-\mathbf y||_1\le2.$$

Hence, we can apply straightforward Theorem \ref{th:regret_omd} with $\eta=\frac{1}{G_\infty}\sqrt{\frac{2\log N}{T}}$ and $\mathbf x_1=(1/N,\ldots,1/N)$ giving as a result the following regret bound:

\begin{equation}
R_T(EG)\le \frac{\epsilon_u}{\epsilon_l}\sqrt{\frac{T\log N}{2}}
\end{equation}


\section{Online Newton Step}

The Online Newton Step (ONS) \cite{hazan2007logarithmic} algorithm is one of the few algorithm other than the UP algorithm that guarantees a logarithmic bound $R_T(ONS)=\mathcal O(\log T)$. The method uses second order information of the loss function, but it can nonetheless stated into first order method such as OMD. 

\begin{definition}(Online Newton Step).
\begin{equation}\label{eq:update_EG}
\mathbf x_{t+1}=\Pi^{A_t}_{\Delta_{N-1}}\left(\mathbf x_t+\frac{1}{\beta}A_t^{-1}\frac{\mathbf y_t}{\langle\mathbf x_t,\mathbf y_t\rangle}\right),
\end{equation}
where $\prod^{A_t}_{\Delta_{N-1}}$ is the non-standard projection onto the simplex $\Delta_{N-1}$ defined as 
$$\Pi^{A_t}_{\Delta_{N-1}}(\mathbf x_0):=\arg\inf\limits_{\mathbf x\in\Delta_{N-1}}\langle\mathbf x-\mathbf x_0,A_t(\mathbf x-\mathbf x_0)\rangle.$$

and the matrix $A_t\in\mathbb R^{N\times N}$ it is defined as $A_t=\sum\limits_{s=1}^t \nabla_t\nabla_t^T+\epsilon\mathbb I_N$\todo{define $\nabla_t$} 
\end{definition}

The idea for the ONS algorithm is originated from the concept of strong convexity, that is defined as follow:

\begin{definition}(Strong Convexity).\label{def:strong_cnvx}
A function $f:\mathcal D\to\mathbb R$ is said to be $\mu$-strong convex w.r.t. the norm $||\cdot||$ if 
$$f(y)-f(x)\ge\langle\nabla f(x),y-x\rangle+\frac{\mu}{2}||y-x||^2,\forall x,y\in\mathcal D,\forall x,y\in\mathcal D$$
\end{definition}

Usually there is the correspondence of convex-loss $R_T=\mathcal O(\sqrt T)$ and strong-convex loss $R_T=\mathcal O(\log T)$. The idea of the ONS algorithm is to recover a weaker concept of strong convexity for exp-concave losses:

\begin{definition}(Weak Strong Convexity).\label{def:weak_strong_cnvx}
A function $f:\mathcal D\to\mathbb R$ is said to be weak-strong convex if $\forall x\in\mathcal D\exists A$ s.t. 
$$f(y)-f(x)\ge\langle\nabla f(x),y-x\rangle+\frac{\mu}{2}||y-x||_{A}^2,$$
for a matrix $A$ that defines the norm $||x||^2_{A}=\langle x, Ax\rangle$.
\end{definition}

In fact for any $\nu$ exp-concave function $f:\mathcal D\to\mathbb R$ with bounded gradient, \emph{i.e.} $||\nabla f(\mathbf x)||_2\le G\ \forall \mathbf x\in\mathcal D$, with $D=\sup\limits_{\mathbf x,\mathbf y\in\mathcal X}||\mathbf x-\mathbf y||_2$, $\beta=\frac{1}{2}\min\{\nu,\frac{1}{4GD}\}$ and $A=\nabla f(\mathbf x)\nabla f(\mathbf x)^T$, we have that 

\begin{equation}\label{eq:weak_strong_conv_exp_concave}
f(\mathbf y)-f(\mathbf x)\ge\langle\nabla f(x),\mathbf y-\mathbf x\rangle+\frac{\beta}{2}||\mathbf y-\mathbf x||_{A}\forall x,y\in\mathcal D.
\end{equation}

The main idea of ONS exploit the weak-strong convexity of exp-concave functions to recover $\mathcal O(\log T)$ regret bounds, the complete proof can be found in \cite{hazan2007logarithmic}.

From Equation \eqref{eq:weak_strong_conv_exp_concave} we can see that the matrix $A_t$ used by the ONS algorithm is just a lower bound on the Hessian of the loss function. This is also why the projection onto the simplex of the ONS algorithm is the non standard projection defined by the matrix $A_t$.

\section{Online Gradient Descent}

The Online Gradient Descent (OGD) algorithm is the first algorithm developed in the field of Online Convex Optimization \cite{zinkevich2003online}. We extended its use to the Online Portfolio Optimization framework, this will be discussed more in details in . \todo{add ch} \todo{continue}

\section{Online Lazy Updates}
\todo{continue}

\section{U$_C$P}
\todo{continue??}

\section{Other Related Works}

There are also heuristic algorithms designed to exploit some known phenomena in markets. Among these heuristic algorithm we can find, Anticor~\cite{borodin2004can}, PAMR~\cite{li2012pamr}, OLMAR~\cite{li2015moving}, and MRTC~\cite{yang2018reversion}, which in some cases outperform the algorithms described above in terms of empirical performance. 
Remarkably, none of the above algorithms provide guarantees on the regret, and so we will avoid an in depth description of their mechanism, since we are currently concerned with algorithm that provide theoretical guarantees without assumptions on the distribution of the marker vectors.

\todo{rephrase}